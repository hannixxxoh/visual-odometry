{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Stitcher(object):\n",
    "    def __init__(self):\n",
    "        self.isv3 = imutils.is_cv3()\n",
    "\n",
    "    def stitch(self, images, ratio=0.75, reprojThresh=4.0, showMatches=False):\n",
    "        (imageB, imageA) = images\n",
    "        (kpsA, featuresA) = self.detectAndDescribe(imageA)\n",
    "        (kpsB, featuresB) = self.detectAndDescribe(imageB)\n",
    "\n",
    "        # match features between the two images\n",
    "        m = self.matchKeypoints(kpsA, kpsB, featuresA, featuresB, ratio, reprojThresh)\n",
    "        if not m:\n",
    "            return None\n",
    "\n",
    "        # otherwise, apply a perspective warp to stitch the images\n",
    "        # together\n",
    "        (matches, H, status) = m\n",
    "        result = cv2.warpPerspective(imageA, H,\n",
    "                                     (imageA.shape[1] + imageB.shape[1], imageA.shape[0]))\n",
    "        result[0:imageB.shape[0], 0:imageB.shape[1]] = imageB\n",
    "\n",
    "        # check to see if the keypoint matches should be visualized\n",
    "        if showMatches:\n",
    "            vis = self.drawMatches(imageA, imageB, kpsA, kpsB, matches,\n",
    "                                   status)\n",
    "\n",
    "            # return a tuple of the stitched image and the\n",
    "            # visualization\n",
    "            return result, vis\n",
    "\n",
    "        # return the stitched image\n",
    "        return result\n",
    "\n",
    "    def detectAndDescribe(self, image):\n",
    "        # convert the image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # check to see if we are using OpenCV 3.X\n",
    "        if self.isv3:\n",
    "            # detect and extract features from the image\n",
    "            descriptor = cv2.ORB_create()\n",
    "            (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "\n",
    "        # otherwise, we are using OpenCV 2.4.X\n",
    "        else:\n",
    "            # detect keypoints in the image\n",
    "            detector = cv2.ORB_create()\n",
    "            kps = detector.detect(gray)\n",
    "\n",
    "            # extract features from the image\n",
    "            extractor = cv2.ORB_create()\n",
    "            (kps, features) = extractor.compute(gray, kps)\n",
    "\n",
    "        # convert the keypoints from KeyPoint objects to NumPy\n",
    "        # arrays\n",
    "        kps = np.float32([kp.pt for kp in kps])\n",
    "\n",
    "        # return a tuple of keypoints and features\n",
    "        return kps, features\n",
    "\n",
    "    def matchKeypoints(self, kpsA, kpsB, featuresA, featuresB,\n",
    "    ratio, reprojThresh):\n",
    "        # compute the raw matches and initialize the list of actual\n",
    "        # matches\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "        rawMatches = matcher.knnMatch(featuresA, featuresB, 2)\n",
    "        matches = []\n",
    "\n",
    "        # loop over the raw matches\n",
    "        for m in rawMatches:\n",
    "            # ensure the distance is within a certain ratio of each\n",
    "            # other (i.e. Lowe's ratio test)\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "                matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "\n",
    "\n",
    "        # computing a homography requires at least 4 matches\n",
    "        if len(matches) > 4:\n",
    "            # # construct the two sets of points\n",
    "            ptsA = np.float32([kpsA[i] for (_, i) in matches])\n",
    "            ptsB = np.float32([kpsB[i] for (i, _) in matches])\n",
    "\n",
    "\n",
    "            (H, status) = cv2.findHomography(ptsA, ptsB, cv2.RANSAC,\n",
    "                                             reprojThresh)\n",
    "\n",
    "            # return the matches along with the homograpy matrix\n",
    "            # and status of each matched point\n",
    "            return (matches, H, status)\n",
    "\n",
    "        # otherwise, no homograpy could be computed\n",
    "        return None\n",
    "\n",
    "    def drawMatches(self, imageA, imageB, kpsA, kpsB, matches, status):\n",
    "        # initialize the output visualization image\n",
    "        (hA, wA) = imageA.shape[:2]\n",
    "        (hB, wB) = imageB.shape[:2]\n",
    "        vis = np.zeros((max(hA, hB), wA + wB, 3), dtype=\"uint8\")\n",
    "        vis[0:hA, 0:wA] = imageA\n",
    "        vis[0:hB, wA:] = imageB\n",
    "\n",
    "        # loop over the matches\n",
    "        for ((trainIdx, queryIdx), s) in zip(matches, status):\n",
    "            # only process the match if the keypoint was successfully\n",
    "            # matched\n",
    "            if s == 1:\n",
    "                # draw the match\n",
    "                ptA = (int(kpsA[queryIdx][0]), int(kpsA[queryIdx][1]))\n",
    "                ptB = (int(kpsB[trainIdx][0]) + wA, int(kpsB[trainIdx][1]))\n",
    "                cv2.line(vis, ptA, ptB, (0, 255, 0), 1)\n",
    "\n",
    "        # return the visualization\n",
    "        return vis\n",
    "\n",
    "image1 = cv2.imread('sogang1.png')\n",
    "image2 = cv2.imread('sogang2.png')\n",
    "image3 = cv2.imread('sogang3.png')\n",
    "\n",
    "stitcher = Stitcher()\n",
    "(result1, vis1) = stitcher.stitch([image1, image2], showMatches=True)\n",
    "(result2, vis2) = stitcher.stitch([image2, image3], showMatches=True)\n",
    "cv2.imwrite('result1.jpg', result1)\n",
    "cv2.imwrite('result2.jpg', result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image',image3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
